defaults:
  - _self_
  - optimizer: default.yaml
  - scheduler: cyclic.yaml

_target_: twinturbo.src.models.twinturbo_model.TwinTURBO
use_m: True
encoder_mlp_config: 
  hddn_dim: [128, 128, 128, 128]
  act_h: "prelu"
  nrm_on_output: True
  nrm: "batch_nontr"
  nrm_inside: False
decoder_mlp_config:
  hddn_dim: [128, 128, 128, 128]
  act_h: "prelu"
latent_norm: False
latent_dim: 8
loss_cfg:
  reco:
    w: 1
  consistency_x:
    w: 0.001
  consistency_cont: 
    w: 0.001
  second_derivative_smoothness:
    w: 0.0001
    step: 0.1

adversarial_cfg:
  mode: "double_discriminator_priority"
  discriminator:
    hddn_dim: [64, 64, 64, 64]
    act_h: "prelu"
    act_o: "sigmoid"
  discriminator2:
    hddn_dim: [64, 64, 64, 64]
    act_h: "prelu"
    act_o: "sigmoid"
  optimizer_main: default.yaml
  optimizer_d: default.yaml
  warmup: 20
  g_loss_weight: 2
  g_loss_gen_weight: 0.5
  every_n_steps_g: 1
  train_dis_in_warmup: False
  g_loss_weight_in_warmup: True
  loss_function: "binary_cross_entropy"
  scheduler: 
    scheduler_g:
      _target_: torch.optim.lr_scheduler.MultiStepLR
      _partial_: True
      milestones: [50, 100, 150, 200, 250]
      gamma: 0.5
    scheduler_d:
      _target_: torch.optim.lr_scheduler.MultiStepLR
      _partial_: True
      milestones: [50, 100, 150]
      gamma: 0.5
    scheduler_d2:
      _target_: torch.optim.lr_scheduler.MultiStepLR
      _partial_: True
      milestones: [50, 100, 150]
      gamma: 0.5
  gradient_clip_val: 0.1

valid_plots: False