defaults:
  - _self_
  - optimizer: default.yaml
  - scheduler: cyclic.yaml

_target_: twinturbo.src.models.twinturbo_model.TwinTURBO
use_m_encodig: True
network_type: 'Transformer_conditional'
encoder_cfg: 
  transformer:
    _target_: mattstools.mattstools.simple_transformers.TransformerEncoder
    _partial_: true
    dim: 128
    num_layers: 4
    init_method: beit
    layer_config:
      ff_mult: 2
      num_heads: 8
  node_embd_config:
    hddn_dim: 128
    num_blocks: 1
    act_h: silu
    nrm: lyr
  outp_embd_config:
    hddn_dim: 128
    num_blocks: 1
    act_h: silu
    nrm: lyr
  ctxt_embd_config:
    hddn_dim: 128
    outp_dim: 16
    num_blocks: 1
    act_h: silu
    nrm: lyr
decoder_cfg:
  transformer:
    _target_: mattstools.mattstools.simple_transformers.TransformerEncoder
    _partial_: true
    dim: 128
    num_layers: 4
    init_method: beit
    layer_config:
      ff_mult: 2
      num_heads: 8
  node_embd_config:
    hddn_dim: 128
    num_blocks: 1
    act_h: silu
    nrm: lyr
  outp_embd_config:
    hddn_dim: 128
    num_blocks: 1
    act_h: silu
    nrm: lyr
  ctxt_embd_config:
    hddn_dim: 128
    outp_dim: 64
    num_blocks: 1
    act_h: silu
    nrm: lyr
latent_norm: False
latent_dim: 128
loss_cfg:
  reco:
    w: 1

adversarial_cfg:
  mode: "double_discriminator_priority"
  discriminator:
    transformer:
      _target_: mattstools.mattstools.simple_transformers.TransformerEncoder
      _partial_: true
      dim: 128
      num_layers: 4
      init_method: beit
      layer_config:
        ff_mult: 2
        num_heads: 8
    node_embd_config:
      hddn_dim: 128
      num_blocks: 1
      act_h: silu
      nrm: lyr
    outp_embd_config:
      hddn_dim: 128
      num_blocks: 1
      act_h: silu
      nrm: lyr
    ctxt_embd_config:
      hddn_dim: 128
      outp_dim: 64
      num_blocks: 1
      act_h: silu
      nrm: lyr
    final_mlp:
      _target_: mattstools.mattstools.modules.DenseNetwork
      _partial_: true
      act_h: silu
      nrm: layer
      hddn_dim: 32
      num_blocks: 2
  discriminator2:
    hddn_dim: [64, 64, 64, 64]
    act_h: "prelu"
    act_o: "sigmoid"
  optimizer_main: default.yaml
  optimizer_d: default.yaml
  warmup: 20
  g_loss_weight: 2
  g_loss_gen_weight: 0.2
  every_n_steps_g: 1
  train_dis_in_warmup: False
  g_loss_weight_in_warmup: True
  loss_function: "binary_cross_entropy"
  scheduler: 
    scheduler_g:
      _target_: torch.optim.lr_scheduler.MultiStepLR
      _partial_: True
      milestones: [50, 100, 150, 200, 250]
      gamma: 0.5
    scheduler_d:
      _target_: torch.optim.lr_scheduler.MultiStepLR
      _partial_: True
      milestones: [50, 100, 150]
      gamma: 0.5
    scheduler_d2:
      _target_: torch.optim.lr_scheduler.MultiStepLR
      _partial_: True
      milestones: [50, 100, 150]
      gamma: 0.5
  gradient_clip_val: 0.1

valid_plots: False



